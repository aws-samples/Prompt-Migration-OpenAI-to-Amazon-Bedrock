{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dab48b5d",
   "metadata": {},
   "source": [
    "# Evaluate Call Summarization for Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645aa75d",
   "metadata": {},
   "source": [
    "In this notebook, we will evaluate metrics such as Alignment, Coverage and overall score of the source and target models using deep eval. Our source model by default is \"mistral.mistral-large-2402-v1:0\" but it can be changed to any other model in the config.py file under /src folder. This notebook also demonstrates using OpenAI as the source model. If you have the OpenAI key, you can invoke the model to generate summaries using OpenAI. As for the Target model, this workshop is designed to work with \"anthropic.claude-3-sonnet-20240229-v1:0\" (Step 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9241d4",
   "metadata": {},
   "source": [
    "![1b3b_Notebook.png](../images/1b3b_Notebook.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d711eb4",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "\n",
    "We start with installing deepeval, openai and langchain libraries\n",
    "Run below cell. You can ignore pip errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dd3ea94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dash 2.17.1 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.17.1 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.17.1 requires dash-table==5.0.0, which is not installed.\n",
      "jupyter-ai 2.18.1 requires faiss-cpu, which is not installed.\n",
      "sagemaker 2.224.1 requires importlib-metadata<7.0,>=1.4.0, but you have importlib-metadata 7.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain 0.1.9 requires langchain-core<0.2,>=0.1.26, but you have langchain-core 0.2.23 which is incompatible.\n",
      "langchain-community 0.0.38 requires langchain-core<0.2.0,>=0.1.52, but you have langchain-core 0.2.23 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install deepeval==0.21.32 --quiet\n",
    "!pip install langchain_aws --quiet\n",
    "!pip install langchain_text_splitters --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0e774",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72fff68",
   "metadata": {},
   "source": [
    "We first define our parameters for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a6b9a95-6f1b-48b0-a52a-9f105202df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "from config import *\n",
    "\n",
    "# src model\n",
    "model_output = \"mistral\"\n",
    "# model_output=\"openai\"\n",
    "# model_output=\"anthropic\"\n",
    "# model_output=\"meta\"\n",
    "\n",
    "# specify prompt_id (\"optimized\" only for anthropic\")\n",
    "prompt_id = \"raw\"\n",
    "# prompt_id=\"optimized\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9348e80-6623-42fb-9f3d-8838809c7bbf",
   "metadata": {},
   "source": [
    "### Standard Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0985af11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_aws import ChatBedrock\n",
    "from datasets import Dataset\n",
    "from ast import literal_eval\n",
    "from botocore.client import Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e9e836",
   "metadata": {},
   "source": [
    "### Import DeepEval Libraries for Summarization Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec496adf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/deepeval/__init__.py:41: UserWarning: You are using deepeval version 0.21.32, however version 0.21.73 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Deep Eval Import\n",
    "sys.path.append(\"../libraries/deep-eval-metrics/\")\n",
    "from deepeval.dataset import EvaluationDataset\n",
    "from deepeval.models.base_model import DeepEvalBaseLLM\n",
    "\n",
    "from deepeval import evaluate\n",
    "from summarization.summarization import SummarizationMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92022799-9bdc-499a-8d81-987394fed11b",
   "metadata": {},
   "source": [
    "## Calculate Summarization Metrics using Deep Eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27ec34d-84e1-4668-acd2-d0cb1d377ba0",
   "metadata": {},
   "source": [
    "#### Instantiate Bedrock Class - Inherits DeepEvalClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f6d8356-98f4-452a-959b-f8a582e55e3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AWSBedrock(DeepEvalBaseLLM):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def load_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        try:\n",
    "            return chat_model.invoke(prompt).content\n",
    "        except:\n",
    "            print(\"Issue with Invoke\")\n",
    "            return self.generate(prompt)\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        chat_model = self.load_model()\n",
    "        try:\n",
    "            res = await chat_model.ainvoke(prompt)\n",
    "            return res.content\n",
    "        except:\n",
    "            print(\"Issue with Invoke\")\n",
    "            return await self.a_generate(prompt)\n",
    "\n",
    "    def get_model_name(self):\n",
    "        return \"Bedrock Model\"\n",
    "\n",
    "\n",
    "# Use of Claude 3 Sonnet\n",
    "custom_model = ChatBedrock(\n",
    "    # credentials_profile_name=\"default\",\n",
    "    region_name=AWS_REGION,\n",
    "    endpoint_url=f\"https://bedrock-runtime.{AWS_REGION}.amazonaws.com\",\n",
    "    model_id=CLAUDE_MODEL_ID,\n",
    "    model_kwargs={\"temperature\": 0.4},\n",
    ")\n",
    "\n",
    "aws_bedrock = AWSBedrock(model=custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e107e",
   "metadata": {},
   "source": [
    "## Calculate Q&A Metrics for Gen AI Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525edd7-286d-4064-a766-4bc1ad1227ab",
   "metadata": {},
   "source": [
    "### Specific summarization output and load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ff134",
   "metadata": {},
   "source": [
    "Load the summarized data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0085fb6-23ec-4c88-a499-fd16448b0bf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../outputs/call_summarization_outputs_mistral.csv\n"
     ]
    }
   ],
   "source": [
    "filename = (\n",
    "    f\"../outputs/call_summarization_outputs_\" + model_output + \".csv\"\n",
    ")  # change filename to the one that needs to be evaluated\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ab89037-aff3-4a01-96ed-5044c0abc17d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_summarization_outputs = pd.read_csv(filename)\n",
    "call_summarization_outputs = call_summarization_outputs.loc[\n",
    "    call_summarization_outputs[\"prompt_id\"] == prompt_id\n",
    "]\n",
    "eval_filename = (\n",
    "    f\"../outputs/call_summarization_eval_\" + prompt_id + \"_\" + model_output + \".csv\"\n",
    ")\n",
    "call_summarization_outputs.to_csv(eval_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ce3fd96-7228-4cb1-85f3-199f7c4af296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>call_id</th>\n",
       "      <th>agent_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>date</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>summary</th>\n",
       "      <th>metric_summary_input_tokens</th>\n",
       "      <th>metric_summary_output_tokens</th>\n",
       "      <th>metric_summary_latency</th>\n",
       "      <th>topic</th>\n",
       "      <th>resolution</th>\n",
       "      <th>root_cause</th>\n",
       "      <th>call_back</th>\n",
       "      <th>next_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C101</td>\n",
       "      <td>1</td>\n",
       "      <td>A01</td>\n",
       "      <td>\\nAgent: Good morning, thank you for calling S...</td>\n",
       "      <td>3/5/24</td>\n",
       "      <td>raw</td>\n",
       "      <td>Sarah, the customer, called SB Bank to inquire...</td>\n",
       "      <td>767</td>\n",
       "      <td>150</td>\n",
       "      <td>4.195616</td>\n",
       "      <td>Credit-Card</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The root cause of the call was the customer's ...</td>\n",
       "      <td>No</td>\n",
       "      <td>Sarah needs to wait for 7-10 business days to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C102</td>\n",
       "      <td>2</td>\n",
       "      <td>A02</td>\n",
       "      <td>Agent: Good morning, thank you for calling SB ...</td>\n",
       "      <td>3/11/24</td>\n",
       "      <td>raw</td>\n",
       "      <td>Sarah Thompson, a customer who applied for a c...</td>\n",
       "      <td>635</td>\n",
       "      <td>184</td>\n",
       "      <td>4.976691</td>\n",
       "      <td>Credit card delivery</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The root cause of the issue was the credit car...</td>\n",
       "      <td>No</td>\n",
       "      <td>Sarah will receive a replacement credit card w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C103</td>\n",
       "      <td>3</td>\n",
       "      <td>A03</td>\n",
       "      <td>\\nAgent: Good morning, thank you for calling S...</td>\n",
       "      <td>2/29/24</td>\n",
       "      <td>raw</td>\n",
       "      <td>The customer, Sarah, was affected by recent fl...</td>\n",
       "      <td>676</td>\n",
       "      <td>121</td>\n",
       "      <td>3.438767</td>\n",
       "      <td>Extension</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The root cause was the recent floods in Califo...</td>\n",
       "      <td>No</td>\n",
       "      <td>The next step is for Sarah to make her minimum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C104</td>\n",
       "      <td>4</td>\n",
       "      <td>A04</td>\n",
       "      <td>\\nAgent: Good morning, thank you for calling S...</td>\n",
       "      <td>3/7/24</td>\n",
       "      <td>raw</td>\n",
       "      <td>The customer, Sarah, was incorrectly charged a...</td>\n",
       "      <td>680</td>\n",
       "      <td>154</td>\n",
       "      <td>4.216477</td>\n",
       "      <td>Refund</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The root cause of the issue was a temporary sy...</td>\n",
       "      <td>No</td>\n",
       "      <td>The next steps are for the customer to wait fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C105</td>\n",
       "      <td>5</td>\n",
       "      <td>A05</td>\n",
       "      <td>\\nAgent: Good morning, thank you for calling S...</td>\n",
       "      <td>2/21/24</td>\n",
       "      <td>raw</td>\n",
       "      <td>Sarah Thompson reported a fraudulent transacti...</td>\n",
       "      <td>850</td>\n",
       "      <td>155</td>\n",
       "      <td>4.327091</td>\n",
       "      <td>Fraud</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The root cause of the call was a fraudulent ai...</td>\n",
       "      <td>No</td>\n",
       "      <td>The next steps are for the agent to pass the d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  call_id agent_id  \\\n",
       "0        C101        1      A01   \n",
       "1        C102        2      A02   \n",
       "2        C103        3      A03   \n",
       "3        C104        4      A04   \n",
       "4        C105        5      A05   \n",
       "\n",
       "                                          transcript     date prompt_id  \\\n",
       "0  \\nAgent: Good morning, thank you for calling S...   3/5/24       raw   \n",
       "1  Agent: Good morning, thank you for calling SB ...  3/11/24       raw   \n",
       "2  \\nAgent: Good morning, thank you for calling S...  2/29/24       raw   \n",
       "3  \\nAgent: Good morning, thank you for calling S...   3/7/24       raw   \n",
       "4  \\nAgent: Good morning, thank you for calling S...  2/21/24       raw   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Sarah, the customer, called SB Bank to inquire...   \n",
       "1  Sarah Thompson, a customer who applied for a c...   \n",
       "2  The customer, Sarah, was affected by recent fl...   \n",
       "3  The customer, Sarah, was incorrectly charged a...   \n",
       "4  Sarah Thompson reported a fraudulent transacti...   \n",
       "\n",
       "   metric_summary_input_tokens  metric_summary_output_tokens  \\\n",
       "0                          767                           150   \n",
       "1                          635                           184   \n",
       "2                          676                           121   \n",
       "3                          680                           154   \n",
       "4                          850                           155   \n",
       "\n",
       "   metric_summary_latency                 topic resolution  \\\n",
       "0                4.195616           Credit-Card        Yes   \n",
       "1                4.976691  Credit card delivery        Yes   \n",
       "2                3.438767             Extension        Yes   \n",
       "3                4.216477                Refund        Yes   \n",
       "4                4.327091                 Fraud        Yes   \n",
       "\n",
       "                                          root_cause call_back  \\\n",
       "0  The root cause of the call was the customer's ...        No   \n",
       "1  The root cause of the issue was the credit car...        No   \n",
       "2  The root cause was the recent floods in Califo...        No   \n",
       "3  The root cause of the issue was a temporary sy...        No   \n",
       "4  The root cause of the call was a fraudulent ai...        No   \n",
       "\n",
       "                                          next_steps  \n",
       "0  Sarah needs to wait for 7-10 business days to ...  \n",
       "1  Sarah will receive a replacement credit card w...  \n",
       "2  The next step is for Sarah to make her minimum...  \n",
       "3  The next steps are for the customer to wait fo...  \n",
       "4  The next steps are for the agent to pass the d...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_summarization_outputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad82b10",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52275707",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_summarization_outputs[\"transcript\"] = (\n",
    "    call_summarization_outputs[\"transcript\"]\n",
    "    .apply(lambda x: x.replace(r\"'\", r\"\\'\"))\n",
    "    .apply(lambda x: \"['''\" + x + \"''']\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6632c6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_summarization_outputs[\"transcript\"] = call_summarization_outputs[\n",
    "    \"transcript\"\n",
    "].apply(literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6292a06",
   "metadata": {},
   "source": [
    "## Calculate Summarization Metrics for Call Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95086c8-bcbb-40fc-93c3-0d97efed4358",
   "metadata": {},
   "source": [
    "For deep eval, context is the ideal context which typically comes from the evaluation dataset. However, retrieval context is the actual context that is being retrieved at runtime. So you could say that the context is a \"ground truth\" context while the retrieval context is the actual context. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29bd683",
   "metadata": {},
   "source": [
    "### Description of Metrics for Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c48a3",
   "metadata": {},
   "source": [
    "**Alignment**: This metric measures the amount of detail included in the summary from the original text. \n",
    "\n",
    "Algorithm \n",
    "1. Given the original text, an LLM generates ‘n’ questions. \n",
    "2. For each of the ‘n’ questions, the LLM evaluates whether it can be answered from the summarized text. If not, the summary doesn’t contain enough information. 3. Returns the percentage of the ‘n’ questions that can be answered by the summary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1687e94",
   "metadata": {},
   "source": [
    "**Coverage**: This metric measures the factual alignment between the original text and the summary. \n",
    "\n",
    "Algorithm \n",
    "1. Given the summary, an LLM generates ‘n’ questions. \n",
    "2. The evaluation LLM generates answers to those ‘n’ questions from the summary and the original text. \n",
    "3. Returns the percentage of the ‘n’ questions whose answers from the original text and summary are the same (the evaluation LLM determines whether these answers are semantically the same)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f4512",
   "metadata": {},
   "source": [
    "Source: https://www.confident-ai.com/blog/a-step-by-step-guide-to-evaluating-an-llm-text-summarization-task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e5f41",
   "metadata": {},
   "source": [
    "### Use DeepEval to Calculate Summarization Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f3a3f2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c088261",
   "metadata": {},
   "source": [
    "Source: https://github.com/confident-ai/deepeval/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b26dcd5-cb6a-46e4-8751-9775db1756f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "field_to_question_map = {\"summary\": \"What is the summary of the transcript?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7437fd10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/portalocker/utils.py:216: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/portalocker/utils.py:216: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/portalocker/utils.py:216: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/portalocker/utils.py:216: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/portalocker/utils.py:216: UserWarning: timeout has no effect in blocking mode\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✅ Tests finished! Run <span style=\"color: #008000; text-decoration-color: #008000\">\"deepeval login\"</span> to view evaluation results on the web.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✅ Tests finished! Run \u001b[32m\"deepeval login\"\u001b[0m to view evaluation results on the web.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarization_metric = SummarizationMetric(model=aws_bedrock)\n",
    "summary_dataset = EvaluationDataset()\n",
    "summary_dataset.add_test_cases_from_csv_file(\n",
    "    file_path=eval_filename,\n",
    "    input_col_name=\"transcript\",\n",
    "    actual_output_col_name=\"summary\",\n",
    "    # expected_output_col_name='summary',\n",
    ")\n",
    "summary_result = evaluate(\n",
    "    summary_dataset, [summarization_metric], run_async=False, print_results=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "141cc421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alignments = []\n",
    "coverages = []\n",
    "overal_scores = []\n",
    "for res in summary_result:\n",
    "    scores = res.metrics[0].score_breakdown\n",
    "    alignments += [scores[\"Alignment\"]]\n",
    "    coverages += [scores[\"Coverage\"]]\n",
    "    overal_scores += [res.metrics[0].score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14c650a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"transcripts\": call_summarization_outputs[\"transcript\"],\n",
    "    \"summary\": call_summarization_outputs[\"summary\"],\n",
    "    \"alignment\": alignments,\n",
    "    \"coverage\": coverages,\n",
    "    \"overal_score\": overal_scores,\n",
    "}\n",
    "# Create DataFrame\n",
    "df_summary_eval = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e27c78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripts</th>\n",
       "      <th>summary</th>\n",
       "      <th>alignment</th>\n",
       "      <th>coverage</th>\n",
       "      <th>overal_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\\nAgent: Good morning, thank you for calling ...</td>\n",
       "      <td>Sarah, the customer, called SB Bank to inquire...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Agent: Good morning, thank you for calling SB...</td>\n",
       "      <td>Sarah Thompson, a customer who applied for a c...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\\nAgent: Good morning, thank you for calling ...</td>\n",
       "      <td>The customer, Sarah, was affected by recent fl...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\\nAgent: Good morning, thank you for calling ...</td>\n",
       "      <td>The customer, Sarah, was incorrectly charged a...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\\nAgent: Good morning, thank you for calling ...</td>\n",
       "      <td>Sarah Thompson reported a fraudulent transacti...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         transcripts  \\\n",
       "0  [\\nAgent: Good morning, thank you for calling ...   \n",
       "1  [Agent: Good morning, thank you for calling SB...   \n",
       "2  [\\nAgent: Good morning, thank you for calling ...   \n",
       "3  [\\nAgent: Good morning, thank you for calling ...   \n",
       "4  [\\nAgent: Good morning, thank you for calling ...   \n",
       "\n",
       "                                             summary  alignment  coverage  \\\n",
       "0  Sarah, the customer, called SB Bank to inquire...   0.500000       1.0   \n",
       "1  Sarah Thompson, a customer who applied for a c...   1.000000       0.0   \n",
       "2  The customer, Sarah, was affected by recent fl...   1.000000       0.0   \n",
       "3  The customer, Sarah, was incorrectly charged a...   1.000000       0.0   \n",
       "4  Sarah Thompson reported a fraudulent transacti...   0.666667       0.0   \n",
       "\n",
       "   overal_score  \n",
       "0           0.5  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4b964a7-1cbb-41b3-82f8-5bb11426a45f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcripts</th>\n",
       "      <th>summary</th>\n",
       "      <th>alignment</th>\n",
       "      <th>coverage</th>\n",
       "      <th>overal_score</th>\n",
       "      <th>metric_summary_input_tokens</th>\n",
       "      <th>metric_summary_output_tokens</th>\n",
       "      <th>metric_summary_latency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\\nAgent: Good morning, thank you for calling ...</td>\n",
       "      <td>Sarah, the customer, called SB Bank to inquire...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>767</td>\n",
       "      <td>150</td>\n",
       "      <td>4.195616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Agent: Good morning, thank you for calling SB...</td>\n",
       "      <td>Sarah Thompson, a customer who applied for a c...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>635</td>\n",
       "      <td>184</td>\n",
       "      <td>4.976691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\\nAgent: Good morning, thank you for calling ...</td>\n",
       "      <td>The customer, Sarah, was affected by recent fl...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>676</td>\n",
       "      <td>121</td>\n",
       "      <td>3.438767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\\nAgent: Good morning, thank you for calling ...</td>\n",
       "      <td>The customer, Sarah, was incorrectly charged a...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>680</td>\n",
       "      <td>154</td>\n",
       "      <td>4.216477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\\nAgent: Good morning, thank you for calling ...</td>\n",
       "      <td>Sarah Thompson reported a fraudulent transacti...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850</td>\n",
       "      <td>155</td>\n",
       "      <td>4.327091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         transcripts  \\\n",
       "0  [\\nAgent: Good morning, thank you for calling ...   \n",
       "1  [Agent: Good morning, thank you for calling SB...   \n",
       "2  [\\nAgent: Good morning, thank you for calling ...   \n",
       "3  [\\nAgent: Good morning, thank you for calling ...   \n",
       "4  [\\nAgent: Good morning, thank you for calling ...   \n",
       "\n",
       "                                             summary  alignment  coverage  \\\n",
       "0  Sarah, the customer, called SB Bank to inquire...   0.500000       1.0   \n",
       "1  Sarah Thompson, a customer who applied for a c...   1.000000       0.0   \n",
       "2  The customer, Sarah, was affected by recent fl...   1.000000       0.0   \n",
       "3  The customer, Sarah, was incorrectly charged a...   1.000000       0.0   \n",
       "4  Sarah Thompson reported a fraudulent transacti...   0.666667       0.0   \n",
       "\n",
       "   overal_score  metric_summary_input_tokens  metric_summary_output_tokens  \\\n",
       "0           0.5                          767                           150   \n",
       "1           0.0                          635                           184   \n",
       "2           0.0                          676                           121   \n",
       "3           0.0                          680                           154   \n",
       "4           0.0                          850                           155   \n",
       "\n",
       "   metric_summary_latency  \n",
       "0                4.195616  \n",
       "1                4.976691  \n",
       "2                3.438767  \n",
       "3                4.216477  \n",
       "4                4.327091  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_eval = pd.concat(\n",
    "    [\n",
    "        df_summary_eval,\n",
    "        call_summarization_outputs[\n",
    "            [\n",
    "                \"metric_summary_input_tokens\",\n",
    "                \"metric_summary_output_tokens\",\n",
    "                \"metric_summary_latency\",\n",
    "            ]\n",
    "        ],\n",
    "    ],\n",
    "    axis=1,\n",
    "    join=\"inner\",\n",
    ")\n",
    "final_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae24b930-6474-42e9-ae99-315cdac80414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_eval.to_csv(eval_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24f3f347-8020-46b5-aa78-0ee0152a1a98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric \t mean \t median\n",
      "alignment\t0.8333333333333334\t1.0\n",
      "coverage\t0.2\t0.0\n",
      "overal_score\t0.1\t0.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"metric \\t mean \\t median\")\n",
    "for metric in [\"alignment\", \"coverage\", \"overal_score\"]:\n",
    "    print(\n",
    "        f\"{metric}\\t{df_summary_eval[metric].mean()}\\t{df_summary_eval[metric].median()}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
