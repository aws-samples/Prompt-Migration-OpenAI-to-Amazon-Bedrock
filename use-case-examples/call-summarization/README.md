# Evaluate and Migrate FMs to Amazon Bedrock

This repository contains pre-built examples to help customers get started with the migration of FMs to Amazon Bedrock.

## Getting Started

To get started with the code examples, ensure you have access to [Amazon Bedrock](https://aws.amazon.com/bedrock/) and Amazon SageMaker. Then clone this repo in SageMaker JupyterLab and navigate to one of the folders above. Detailed instructions are provided in each folder's README.

### Enable AWS IAM permissions for Bedrock

The AWS identity you assume from your environment (which is the [*Studio/notebook Execution Role*](https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-roles.html) from SageMaker, or could be a role or IAM User for self-managed notebooks or other use-cases), must have sufficient [AWS IAM permissions](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies.html) to call the Amazon Bedrock service.

To grant Bedrock access to your identity, you can:

- Open the [AWS IAM Console](https://us-east-1.console.aws.amazon.com/iam/home?#)
- Find your [Role](https://us-east-1.console.aws.amazon.com/iamv2/home?#/roles) (if using SageMaker or otherwise assuming an IAM Role), or else [User](https://us-east-1.console.aws.amazon.com/iamv2/home?#/users)
- Select *Add Permissions > Create Inline Policy* to attach new inline permissions, open the *JSON* editor and paste in the below example policy:

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "BedrockFullAccess",
            "Effect": "Allow",
            "Action": ["bedrock:*"],
            "Resource": "*"
        }
    ]
}
```

> ⚠️ **Note:** With Amazon SageMaker, your notebook execution role will typically be *separate* from the user or role that you log in to the AWS Console with. If you'd like to explore the AWS Console for Amazon Bedrock, you'll need to grant permissions to your Console user/role too.

For more information on the fine-grained action and resource permissions in Bedrock, check out the Bedrock Developer Guide.

## Prerequisites
The collected information includes:
- Use case : Call Script Summarization
- Input data and information : A .csv file (data/call_transcripts.csv) having the following fields-
    - customer_id
    - call_id
    - agent_id
    - transcript
    - date
- Source model prompts : A .csv file (data/call_summarization_prompts.csv) having following fields -
    - prompt_id
    - prompt_text


## Select GenAI use case base evaluation framework and metrics
- Evaluation framework: We use [DeepEval](https://docs.confident-ai.com/docs/getting-started), an open-source evaluation framework for text summarization use cases. This includes call script summarization.
- Metrics: We use [Summarization metric](https://docs.confident-ai.com/docs/metrics-summarization), which uses LLMs to determine whether your LLM (application) is generating factually correct summaries while including the neccessary details from the original text.

## Input data and information
The sample call transcipt input file data/call_transcripts.csv includes 5 examples of call transcripts that were generated by Amazon Bedrock Claude. To add your own data, make sure that each sample has a transcript field.

## Source model prompts
The sample prompts files data/call_summarization_prompts.csv includes one example of the prompt from the source model.

## Contributing

We welcome community contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This library is licensed under the MIT-0 License. See the [LICENSE](LICENSE) file.